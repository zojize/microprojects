{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "<h1 style=\"text-align: center\">\n",
    "<div style=\"color: #DD3403; font-size: 60%\">Data Science DISCOVERY MicroProject</div>\n",
    "<span style=\"\">MicroProject: World University Rankings</span>\n",
    "<div style=\"font-size: 60%;\"><a href=\"https://discovery.cs.illinois.edu/microproject/world-university-rankings/\">https://discovery.cs.illinois.edu/microproject/world-university-rankings/</a></div>\n",
    "</h1>\n",
    "\n",
    "<hr style=\"color: #DD3403;\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Source: The Times Higher Education\n",
    "\n",
    "There are hundreds of organizations that rank universities, including US News and World Report, QS World University Rankings, Times Higher Education (THE), and many others.\n",
    "\n",
    "The Times Higher Education (THE) provides a clean, well-documented CSV that includes their rankings based on the \"performance data on universities for students and their families, academics, university leaders, governments and industry\".  Their 2020 dataset includes almost 1,400 universities across 92 countries and includes 13 performance indicators that measure an institution’s performance across teaching, research, knowledge transfer and international outlook.  Their website with additional details on this dataset is found here: https://www.timeshighereducation.com/content/world-university-rankings\n",
    "\n",
    "In this MicroProject, you will explore basic DataFrame operations on the Times Higher Education university rankings."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "<hr style=\"color: #DD3403;\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing the World University Rank Dataset\n",
    "\n",
    "To use the `pandas` library, we must **import** it into your notebook. import pandas as `pd` in the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "Use panda's `read_csv` function to read the `World_University_Rank_2020.csv` (already provided for you) and store that data into a DataFrame called `df`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV into a new DataFrame `df`:\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEST CASE for Importing the World University Rank Dataset\n",
    "#\n",
    "# What is this cell?\n",
    "# - This cell contains test cases for the MicroProject. Even though you can modify this\n",
    "#   cell, you should treat it like it's a read-only cell since it will be replaced with\n",
    "#   a fresh version when your code is checked.\n",
    "#\n",
    "# - If this cell runs without any error in the output, you PASSED all test cases!\n",
    "#   We try and make these test cases as useful and complete as possible, but there is\n",
    "#   a chance your code may be incorrect even though you pass the test cases (these\n",
    "#   tests should be seen as a way to give you confidence that code you believe is\n",
    "#   actually correct, not as a robust check to catch all possible errors).\n",
    "#\n",
    "# - If this cell results in any errors, check you previous cells, make changes, and\n",
    "#   RE-RUN your code and then re-run this cell.  Keep repeating this until the cell\n",
    "#   passed with no errors! :)\n",
    "\n",
    "tada = \"\\N{PARTY POPPER}\"\n",
    "\n",
    "assert(\"df\" in vars()), \"Make sure to name the dataframe df\"\n",
    "assert(df[\"University\"].iloc[0] == \"University of Oxford\")\n",
    "assert(df[\"University\"].iloc[1392] == \"Pontifical Catholic University of Minas Gerais\")\n",
    "assert(\"University\" in df)\n",
    "assert(\"Score\" not in df)\n",
    "print(f\"{tada} All Tests Passed! {tada}\") "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "<hr style=\"color: #DD3403;\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Puzzle 1: Rankings with the United States\n",
    "\n",
    "In this dataset, each row represents one university.\n",
    "\n",
    "Find the variable that encodes where the university is located.  Using a conditional, create a new DataFrame called `df_US` that includes the subset of data containing only the universities in the United States:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_US = ...\n",
    "df_US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEST CASE for Puzzle 1: Rankings with the United States\n",
    "#\n",
    "# What is this cell?\n",
    "# - This cell contains test cases for the MicroProject. Even though you can modify this\n",
    "#   cell, you should treat it like it's a read-only cell since it will be replaced with\n",
    "#   a fresh version when your code is checked.\n",
    "#\n",
    "# - If this cell runs without any error in the output, you PASSED all test cases!\n",
    "#   We try and make these test cases as useful and complete as possible, but there is\n",
    "#   a chance your code may be incorrect even though you pass the test cases (these\n",
    "#   tests should be seen as a way to give you confidence that code you believe is\n",
    "#   actually correct, not as a robust check to catch all possible errors).\n",
    "#\n",
    "# - If this cell results in any errors, check you previous cells, make changes, and\n",
    "#   RE-RUN your code and then re-run this cell.  Keep repeating this until the cell\n",
    "#   passed with no errors! :)\n",
    "\n",
    "tada = \"\\N{PARTY POPPER}\"\n",
    "\n",
    "assert(df.iloc[47][\"University\"] == \"University of Illinois at Urbana-Champaign\")\n",
    "assert(df.iloc[47][\"Number_students\"] == 44916)\n",
    "\n",
    "assert('df_US' in vars()), \"Make sure to name the dataframe df_US.\"\n",
    "assert(len(df_US) == 172), \"It looks like you did not subset df_US to only include universities located in the United States.\"\n",
    "assert(df_US[\"University\"].iloc[0] == \"California Institute of Technology\")\n",
    "assert(df_US[\"Number_students\"].iloc[171] == 14791)\n",
    "\n",
    "print(f\"{tada} All Tests Passed! {tada}\") "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "## **Key Idea**: Indexes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "By default, pandas creates an **index column** that will always start with the index `0`.  Each row after the first receives an index in an increasing order (the second row has index `1`, the third row index `2`, and so on).\n",
    "\n",
    "The Top University in the full original dataset, Oxford, has an index of 0.  Using the full original dataset (`df`), `df.loc[0]` will display the row at the index (or `loc`) `0`.  See this yourself in running the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the row with the index `0` in the DataFrame `df`:\n",
    "df.loc[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Indexes after Row Selection\n",
    "\n",
    "Our dataset of US-based universities -- `df_US` -- is a subset of the original full dataset and **still has the original index values**.\n",
    "\n",
    "When we attempt to find index `0` of `df_US`, we **expect to get a `KeyError`** indicating that this index does NOT exist within `df_US`.  Try this yourself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the row with the index `0` in the DataFrame `df_US`:\n",
    "#          ** An error in expected!! **\n",
    "#   ** (You will fix it in the next section.) **\n",
    "df_US.loc[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Fix The KeyError\n",
    "\n",
    "(⚠️ You **MUST** make the fix for grading to work, it's easy to miss this section! ⚠️)\n",
    "\n",
    "In the above cell, fix the error by updating the code to select the best University in `df_US`.\n",
    "\n",
    "Fix it and re-run the cell before you continue to the next puzzle. :)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "<hr style=\"color: #DD3403; border-style: dashed;\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Puzzle 1.2: Re-indexing the Universities in the United States\n",
    "\n",
    "The command `df_US.reset_index()` can be used to **regenerate** the indexes for `df_US`.\n",
    "\n",
    "When you run `reset_index`, the pandas library will:\n",
    "1. Move the existing indexes to a new column called `index`\n",
    "2. Then, replace all of the indexes in `df_US` with a new index (starting with `0`, and counting up by one for each row, just like it was a new dataset)\n",
    "\n",
    "Use the `reset_index()` function on `df_US` to reset the indexes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_US = ...\n",
    "df_US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEST CASE for Puzzle 1.2: Re-indexing the universities in the United States\n",
    "#\n",
    "# What is this cell?\n",
    "# - This cell contains test cases for the MicroProject. Even though you can modify this\n",
    "#   cell, you should treat it like it's a read-only cell since it will be replaced with\n",
    "#   a fresh version when your code is checked.\n",
    "#\n",
    "# - If this cell runs without any error in the output, you PASSED all test cases!\n",
    "#   We try and make these test cases as useful and complete as possible, but there is\n",
    "#   a chance your code may be incorrect even though you pass the test cases (these\n",
    "#   tests should be seen as a way to give you confidence that code you believe is\n",
    "#   actually correct, not as a robust check to catch all possible errors).\n",
    "#\n",
    "# - If this cell results in any errors, check you previous cells, make changes, and\n",
    "#   RE-RUN your code and then re-run this cell.  Keep repeating this until the cell\n",
    "#   passed with no errors! :)\n",
    "\n",
    "tada = \"\\N{PARTY POPPER}\"\n",
    "assert(df_US[\"University\"].loc[0] == \"California Institute of Technology\")\n",
    "assert(\"index\" in df_US.columns)\n",
    "print(f\"{tada} All Tests Passed! {tada}\") "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "<hr style=\"color: #DD3403;\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Puzzle 2: Large Universities in the United States\n",
    "\n",
    "In the United States, there are generally large universities (often \"large state schools\") and small universities (often \"small liberal arts colleges\").  Explore the dataset and find the variable that stores the number of students that attends each university.\n",
    "\n",
    "For the next analysis, we want to focus only on **large universities in the United States**.  For the purpose of this analysis, we'll refer to any University with at least 30,000 students as \"large\".\n",
    "\n",
    "Create a new DataFrame called `df_US_large`, which contains all large universities in the United States:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_US_large = ...\n",
    "df_US_large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEST CASE for Puzzle 2: Large universities in the United States\n",
    "#\n",
    "# What is this cell?\n",
    "# - This cell contains test cases for the MicroProject. Even though you can modify this\n",
    "#   cell, you should treat it like it's a read-only cell since it will be replaced with\n",
    "#   a fresh version when your code is checked.\n",
    "#\n",
    "# - If this cell runs without any error in the output, you PASSED all test cases!\n",
    "#   We try and make these test cases as useful and complete as possible, but there is\n",
    "#   a chance your code may be incorrect even though you pass the test cases (these\n",
    "#   tests should be seen as a way to give you confidence that code you believe is\n",
    "#   actually correct, not as a robust check to catch all possible errors).\n",
    "#\n",
    "# - If this cell results in any errors, check you previous cells, make changes, and\n",
    "#   RE-RUN your code and then re-run this cell.  Keep repeating this until the cell\n",
    "#   passed with no errors! :)\n",
    "\n",
    "tada = \"\\N{PARTY POPPER}\"\n",
    "\n",
    "assert('df_US_large' in vars()), \"Make sure to name the dataframe df_US_large.\"\n",
    "assert(len(df_US_large) == 45), \"It looks like you did not subset df_US_large to only universities with at least 30000 students.\"\n",
    "assert(df_US_large[\"University\"].iloc[7] == \"University of Illinois at Urbana-Champaign\")\n",
    "print(f\"{tada} All Tests Passed! {tada}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Puzzle 2.2: Creating a Ranking List of Large US Universities\n",
    "\n",
    "In the THE dataset, the dataset provides a `Score_Rank` column that contains the global rank of each school. For our analysis, we want to add a new column called `US_Large_Rank` that contains the ranking of large schools in the United States.  There are several ways to do this, but one of the easiest is to use the `reset_index()` function.\n",
    "\n",
    "There's three observations we can make:\n",
    "\n",
    "- Since the list is already sorted, we know the first university in `df_US_large` is the top university (Rank #1).  The second row is Rank #2, and so on.\n",
    "- If we use `reset_index`, pandas will re-index the rows starting from zero.\n",
    "- The first row is index 0, which will be Rank #1, so we'd just need to add one to all the index values!\n",
    "\n",
    "Complete the following two steps:\n",
    "1. Use `reset_index()` to reset the index values of `df_US_large`,\n",
    "2. Then, create a new column in `df_US_large` called `\"US_Large_Rank\"` with the value: `df_US_large.index + 1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Reset the index of df_US_large (if needed, see Puzzle 1.2 to refresh how you can do this):\n",
    "df_US_large = ...\n",
    "df_US_large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Create a new column in df_US_large:\n",
    "df_US_large[\"US_large_rank\"] = ...\n",
    "df_US_large"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Viewing the Top Large Schools\n",
    "\n",
    "After all that work, let's check out the top 10 large universities in the United States:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the top ten large universities in the United States:\n",
    "df_US_large.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEST CASE for Puzzle 2.2: Using the index to store a US_large_rank\n",
    "#\n",
    "# What is this cell?\n",
    "# - This cell contains test cases for the MicroProject. Even though you can modify this\n",
    "#   cell, you should treat it like it's a read-only cell since it will be replaced with\n",
    "#   a fresh version when your code is checked.\n",
    "#\n",
    "# - If this cell runs without any error in the output, you PASSED all test cases!\n",
    "#   We try and make these test cases as useful and complete as possible, but there is\n",
    "#   a chance your code may be incorrect even though you pass the test cases (these\n",
    "#   tests should be seen as a way to give you confidence that code you believe is\n",
    "#   actually correct, not as a robust check to catch all possible errors).\n",
    "#\n",
    "# - If this cell results in any errors, check you previous cells, make changes, and\n",
    "#   RE-RUN your code and then re-run this cell.  Keep repeating this until the cell\n",
    "#   passed with no errors! :)\n",
    "\n",
    "tada = \"\\N{PARTY POPPER}\"\n",
    "\n",
    "assert(\"US_large_rank\" in df_US_large)\n",
    "assert(df_US_large.loc[0][0] == df_US_large.iloc[0][0])\n",
    "assert(df_US_large.loc[0][\"US_large_rank\"] == 1)\n",
    "print(f\"{tada} All Tests Passed! {tada}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "<hr style=\"color: #DD3403;\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Puzzle 3: Creating Random Subsets\n",
    "\n",
    "Instead of focusing on just a subset of a DataFrame, researchers often need to look at a random sample of a DataFrame.\n",
    "\n",
    "Returning to the original dataset of nearly 1,400 universities, create one new DataFrame, `df_random_15` , that gives us a random sample of 15 rows in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_random_15 = ...\n",
    "df_random_15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEST CASE for Puzzle 3: Creating random subsets\n",
    "#\n",
    "# What is this cell?\n",
    "# - This cell contains test cases for the MicroProject. Even though you can modify this\n",
    "#   cell, you should treat it like it's a read-only cell since it will be replaced with\n",
    "#   a fresh version when your code is checked.\n",
    "#\n",
    "# - If this cell runs without any error in the output, you PASSED all test cases!\n",
    "#   We try and make these test cases as useful and complete as possible, but there is\n",
    "#   a chance your code may be incorrect even though you pass the test cases (these\n",
    "#   tests should be seen as a way to give you confidence that code you believe is\n",
    "#   actually correct, not as a robust check to catch all possible errors).\n",
    "#\n",
    "# - If this cell results in any errors, check you previous cells, make changes, and\n",
    "#   RE-RUN your code and then re-run this cell.  Keep repeating this until the cell\n",
    "#   passed with no errors! :)\n",
    "\n",
    "tada = \"\\N{PARTY POPPER}\"\n",
    "\n",
    "assert('df_random_15' in vars()), \"Make sure to name the dataframe df_random_15.\"\n",
    "assert(len(df_random_15) == 15), \"It looks like you did not sample exactly 15 rows.\"\n",
    "assert(len(df_random_15[df_random_15.Country != \"United States\"]) > 0), \"Make sure to sample from the full dataset stored in `df`\"\n",
    "print(f\"{tada} All Tests Passed! {tada}\") "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "<hr style=\"color: #DD3403;\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Submission\n",
    "\n",
    "You're almost done!  All you need to do is to commit your lab to GitHub and run the GitHub Actions Grader:\n",
    "\n",
    "1.  ⚠️ **Make certain to save your work.** ⚠️ To do this, go to **File => Save All**\n",
    "\n",
    "2.  After you have saved, exit this notebook and return to https://discovery.cs.illinois.edu/microproject/world-university-rankings/ and complete the section **\"Commit and Grade Your Notebook\"**.\n",
    "\n",
    "3. If you see a 100% grade result on your GitHub Action, you've completed this MicroProject! 🎉\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
